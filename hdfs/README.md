# Ajay Singh
## Master of Science in Computer Science

## Overview
- This assignment is designed to familiarize you with the fundamentals of Apache Hadoop Distributed File System (HDFS). The tasks involve both command-line operations and Python API interactions with HDFS. The goal is to ensure that you not only grasp the basic operations but also learn to navigate documentation for more advanced tasks. Additionally, there's an intriguing hypothetical question related to computing power that encourages you to provide a scientific answer.


### What was the hardest part of this assignment?
- To setup docker and hadoop was the most challenging  part of this assignment. 

### What was the easiest part of this assignment?
- Writing command for shell and python script was easiest.

### Explain all the HDFS commands used for this assignment.
#### shell commands
- mkdir: to create directory
- put: to create file inside directory
- ls: to list the content of directory, -R can be used to list all the files and directories recursively
- cat: to read the content from a file
- mv: to move file from one directory to another, we can change the name of moved file as well
- du: to display disk space used by directory
- rm: to remove the directory, -r can be used to remove all the files and directories recursively

#### python functions
- makedirs: to create directory
- upload: to move file inside directory
- list: to list the content of directory
- read: to read the content from a file
- rename: to move and rename file from one directory to another
- content: to display disk space used by directory
- psp.join: to join the path and child path of the directory
- walk: to traverse on the directory
- delete: to remove the directory
